{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analiza funkcji przydzielającej wartość dopasowania danego tekstu do języka",
   "id": "1988097091ee9713"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Definicja funkcji lang_confidence_score\n",
    "Funkcja oblicza stosunek liczby wystąpień słów tekstu znajdujących się w liście najpopularniejszych słów danego języka do całkowitej liczby słów w tekście.\n"
   ],
   "id": "8722376d72a01728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lang_confidence_score(word_counts, language_words_with_frequency):\n",
    "    number_of_words_from_language = 0\n",
    "    total_number_of_words = 0\n",
    "    # create a set of dictionary keys (lowercase)\n",
    "    set_of_language_words = {w.lower() for w in language_words_with_frequency}\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        total_number_of_words += count\n",
    "        if word.lower() in set_of_language_words:\n",
    "            number_of_words_from_language += count\n",
    "    return number_of_words_from_language / total_number_of_words if total_number_of_words > 0 else 0.0"
   ],
   "id": "11f6e9c300e87b2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pobieranie najczęstszych słów dla języków\n",
    "Pobieramy listę 1000 najczęściej używanych słów dla języka angielskiego (en), polskiego (pl) i francuskiego (fr) z pakietu `wordfreq`.\n",
    "Tworzymy słownik, który dla każdego języka trzyma listę najpopularniejszych słów."
   ],
   "id": "fd7d4844556ec11a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from wordfreq import top_n_list\n",
    "languages_codes = ['en', 'pl', 'fr', 'de']\n",
    "MAX_K = 1000\n",
    "# create a dictionary with a sorted list of words for each language\n",
    "lang_top_words = {code: top_n_list(code, MAX_K) for code in languages_codes}"
   ],
   "id": "d0c79a09d5c67736",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Przygotowanie artykułów z Bulbapedii w języku angielskim\n",
    "Pobieramy dwa artykuły z Bulbapedii\n",
    "1. Dłuższy artykuł o \"Bulbasaur\"\n",
    "2. Artykuł \"List of Japanese Pokémon names\", który jest przykładem tekstu o niskim wyniku dopasowania do języka angielskiego (dużo nazw własnych (nazwy pokemonów))."
   ],
   "id": "abe92ea95bcd74b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scraper_class import Scraper\n",
    "long_wiki_scraper = Scraper(\n",
    "    wiki_url=\"https://bulbapedia.bulbagarden.net/wiki\",\n",
    "    phrase=\"Bulbasaur\"\n",
    ")\n",
    "long_wiki_counts = long_wiki_scraper.count_words()\n",
    "\n",
    "low_wiki_scraper = Scraper(\n",
    "    wiki_url=\"https://bulbapedia.bulbagarden.net/wiki\",\n",
    "    phrase=\"List of Japanese Pokémon names\"\n",
    ")\n",
    "low_wiki_counts=low_wiki_scraper.count_words()"
   ],
   "id": "bc1a43496edbc79b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sprawdźmy poziom dopasowania z językiem angielskim dla tych artykułów:",
   "id": "6c5065065f3e4ca3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Dopasowanie dla artykułu 'Bulbasaur': {lang_confidence_score(long_wiki_counts, lang_top_words['en'])}\")\n",
    "print(f\"Dopasowanie dla artykułu 'List of Japanese Pokémon names': {lang_confidence_score(low_wiki_counts, lang_top_words['en'])}\")"
   ],
   "id": "f0412edba66bca3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Skąd tak niski wynik dla angielskiego artykułu?** Zwróćmy uwagę, że Bulbapedia jest specyficznym wiki skupiającym się na głównie na niesistniejących w rzeczywiśtości krainach, zdarzeniach, stworzeniach itp. W związku z tym jej artykuły w dużej mierze zawierają zmyślone nazwy i słowa niewystępujące oficjalnie w językach, które są używane bardzo rzadko w porównaniu z naturalnymi słowami. Wiedząc to, znalezienie artykułu który mimo, że teoretycznie jest w języku angielskim ,ale który miałby niskie dopasowanie z tym językiem było łatwe, ponieważ polegało na znalezieniu artykułu który jest listą jakichś nieistniejących rzeczywiście obiektów. W tym przypadku są to nazwy pokémonów.\n",
    "\n"
   ],
   "id": "4bc2b1b89b47ec48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pobieranie tekstów spoza Bulbapedii\n",
    "Definiujemy funkcję `get_books_counts`, która pobiera tekst książki z serwisu https://www.gutenberg.org oraz ucina automatyczne informacje dodane do treści książki po czym zwraca obiekt Counter, który dla każdego słowa (znormalizowanego do małych liter i z usuniętymi znakami interpunkcyjnymi) przechowuje liczbę wystąpień w książcę. Czyszczenie tekstu jest szczególnie ważne, ponieważ początkowe i końcowe komentarze są napisane w języku angielskim co zaburza analizę językową.\n"
   ],
   "id": "7558a9093f3fde3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_books_counts(url):\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8' # For non-english characters\n",
    "\n",
    "    full_text = response.text\n",
    "    # Delete automatically added English phrases from the text\n",
    "    start_marker = \"*** START OF THE PROJECT\"\n",
    "    end_marker = \"*** END OF THE PROJECT\"\n",
    "\n",
    "    start_index = 0\n",
    "    start_marker_position = full_text.find(start_marker)\n",
    "    if start_marker_position != -1:\n",
    "        # end of the *** START OF THE ... *** line\n",
    "        start_index = full_text.find(\"\\n\", start_marker_position) + 1\n",
    "\n",
    "    end_index = len(full_text)\n",
    "    end_marker_position = full_text.find(end_marker)\n",
    "    if end_marker_position != -1:\n",
    "        end_index = end_marker_position\n",
    "\n",
    "    # get text without English description\n",
    "    real_text = full_text[start_index:end_index]\n",
    "\n",
    "    # convert text to lowercase\n",
    "    raw_text = real_text.lower()\n",
    "    raw_words = raw_text.split()\n",
    "    words = []\n",
    "    for word in raw_words:\n",
    "        # Remove punctuation from the end and beginning of the words\n",
    "        cleaned = re.sub(r'^\\W+|\\W+$', ' ', word, flags=re.UNICODE).strip()\n",
    "        if cleaned:\n",
    "            words.append(cleaned)\n",
    "    return Counter(words)\n"
   ],
   "id": "d0fa5db0db78406f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pobieranie konkretnych książek w różnych językach\n",
    "Pobieramy \"Pana Tadeusza\" (w języku polskim), \"Robinsona Crusoe\" (w języku angielskim) oraz \"Dwadzieścia tysięcy mil podmorskiej żeglugi\" (w języku francuskim).\n"
   ],
   "id": "88957915b9e5e909"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "books_texts_counts = {\n",
    "    \"pl\": get_books_counts(\"https://www.gutenberg.org/cache/epub/31536/pg31536.txt\"),\n",
    "    \"en\": get_books_counts(\"https://www.gutenberg.org/cache/epub/70841/pg70841.txt\"),\n",
    "    \"fr\": get_books_counts(\"https://www.gutenberg.org/cache/epub/54873/pg54873.txt\"),\n",
    "    \"de\": get_books_counts(\"https://www.gutenberg.org/cache/epub/21000/pg21000.txt\")\n",
    "}\n"
   ],
   "id": "f59b4076d8bf7514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Obliczanie wyników dla różnych wartości k\n",
    "Obliczamy wyniki funkcji `lang_confidence_score` dla każdej trójki: (badany język, liczba wystąpień słów w tekście, lista k najczęstszych słów w badanym języku)"
   ],
   "id": "27e95b9a19d6baa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_for_texts = [\n",
    "    {\"name\": \"Bulbasaur (EN, duże wiki)\", \"counts\": long_wiki_counts},\n",
    "    {\"name\": \"List of Japanese Pokémon names  (EN, trudne wiki)\", \"counts\": low_wiki_counts},\n",
    "    {\"name\": \"Pan Tadeusz (PL)\", \"counts\": books_texts_counts['pl']},\n",
    "    {\"name\": \"Robinson Crusoe (EN)\", \"counts\": books_texts_counts['en']},\n",
    "    {\"name\": \"Dwadzieścia Tysięcy Mil Podmorskiej Żeglugi (FR)\", \"counts\": books_texts_counts['fr']},\n",
    "    {\"name\": \"Faust\", \"counts\": books_texts_counts['de']}\n",
    "]\n",
    "\n",
    "languages = ['en', 'pl', 'fr', 'de']\n",
    "k_values = [3, 10, 100, 1000]\n",
    "data = []\n",
    "\n",
    "for result in results_for_texts:\n",
    "    for lang in languages:\n",
    "        for k in k_values:\n",
    "            top_k_words = lang_top_words[lang][:k]\n",
    "            score = lang_confidence_score(result[\"counts\"], top_k_words)\n",
    "            data.append({\n",
    "                \"Nazwa Tekstu\": result[\"name\"],\n",
    "                \"Język\": lang,\n",
    "                \"Wynik\": score,\n",
    "                \"k\": k\n",
    "            })\n",
    "df = pd.DataFrame(data)\n"
   ],
   "id": "adf991ed60670e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Wizualizacja wyników\n",
    "Definiujemy funkcję `create_chart`, która generuje wykres słupkowy dla danej wartości `k`, przedstawiając wyniki dopasowania dla różnych tekstów i języków.\n"
   ],
   "id": "e7d904bfefa83386"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_chart(dataframe, k_val):\n",
    "    df_for_k = dataframe[df['k'] == k_val]\n",
    "    df_plot = df_for_k.pivot(index='Nazwa Tekstu', columns='Język', values='Wynik')\n",
    "    df_plot.plot(kind='bar', figsize=(8, 5), color=['blue', 'green', 'red', 'yellow'])\n",
    "    plt.ylim(0,1) # Strict limits of Y axis\n",
    "    plt.title(f\"Dopasowanie języka dla k = {k_val}\")\n",
    "    plt.ylabel(\"Wynik dopasowania [0..1]\")\n",
    "    plt.xticks(rotation=20, ha='right') # Rotate text names\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "4b39e83886ecf44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generowanie wykresów\n",
    "Poniżej znajdują się wykresy dla kolejnych wartości `k`\n"
   ],
   "id": "a0e9c7b68be351b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_chart(df, 3)\n",
   "id": "d8171313dfbbef07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dla **k=3** (tylko 3 najpopularniejsze słowa w danym języku) wykres pokazuje że wartości dopasowania są niskie (nie przekraczają 0.2) dla wszystkich kombinacji języka i tekstu. Można zauważyć że każdy tekst poza trudnym artykułem ma wyraźnie największe dopasowanie ze swoim rzeczywistym językiem. W przypadku trudnego artykułu z większością nazw własnych dla każdego języka te wartości są bliskie zeru. Dodatkowo zauważyć można, że wyłacznie natywnie francuski tekst ma niezerową zgodność z językiem francuskim oraz natywnie francuski tekst ma zerowe dopasowanie z każdym z obcych języków. Zauważalny poziom dopasowania tekstów angielskich z językiem polskim wynika z faktu, że niektóre z najpopularniejszych słów języka angielskiego występują często w języku polskim.",
   "id": "980e65514f60869"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_chart(df, 10)\n",
   "id": "26dbc3c4037a084f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dla **k=10** (10 najpopularniejszych słów w danym języku) wyraźnie widać wzrost dopasowania dla tekstów z ich rzeczywistymi językami. W każdym prawie przypadku (poza trudnym artykułem dla którego wszystkie wartości są bliskie zeru) różnica pomiędzy dopasowaniem dla języka rzeczywistego a dopasowaniami dla języków obcych się zwiększyła. W dalszym ciągu francuski tekst ma niezerowe dopasowanie wyłącznie z językiem francuskim oraz teskty w innych językach nie mają dopasowania z językiem francuskim.",
   "id": "a0ae1e335692f13b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_chart(df, 100)\n",
   "id": "3d84fc171d579e98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dla **k=100** (100 najpopularniejszych słów w danym języku) Różnice dopasowań tekstów do ich rzeczywistych języków jeszcze wyraźniej odbiegają od dopasowań do języków obcych. Zaczęły pojawiać się niewielkie dopasowania między językiem francuskim a tekstami w innych językach. Teraz wyraźnie widać że teskt natywnie polski ma dopasowanie do języka polskiego na poziomie 0.30 podczas gdy tekst francuski ma z językiem francuskim ponad 0.4, a tekst angielski z językiem angielskim ma prawie 0.6.",
   "id": "423d5030b81ce0ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_chart(df, 1000)",
   "id": "c4072cba1a89dea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dla **k=1000** (1000 najpopularniejszych słów w danym języku) Wyraźnie widać, że spośród dopasowań długiego tekstu ze swoim natywnym językiem, język polski osiąga zdecydowanie najniższe wyniki (Pan Tadeusz ma dopasowanie z językiem polskim na poziomie 0.4). Bardzo zauważalne są względnie wysokie dopasowania tekstów angielskich do języka polskiego oraz francuskiego (dla Robinsona Crusoe na poziomie 0.3) chociaż mimo tego, dopasowania tekstów z ich natywnymi językami są znacząco większe od dopasowań z innymi językami (poza trudnym artykułem, który tak naprawdę zawiera pdoobną ilośc słów w każdym z badanych języków, gdyż w większości posiada słowa niewystępujące w żadnym z tych języków)\n",
   "id": "bbc0e14353bb44f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wnioski\n",
   "id": "46c4fc6afb10937"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Skuteczność metody `lang_confidence_score`**: Dla każdego testowanego k, każdy tekst miał największe dopasowanie ze swoim natywnym językiem co sugeruje pewną skuteczność zaproponowanej metody do mierzenia dopasowań z językiem. Jednak zauważalnym problemem jest przypisywanie względnie wysokich dopasowań tekstu do języków obcych dla dużego k. Np \"Robinson Crusoe\" napisany w języku angielskim dla k=1000 ma dopasowanie z językiem polskim na poziomie 0.3, a \"Pan Tadeusz\" napisany w języku polskim ma dopasowanie niewiele większe niz 0.4. Mimo że dla większych k, dopasowania tekstu do jego natywnego języka są znacznie większe niż dopasowania tego tekstu do języków obcych, to tak bliskie wartości (jak te opisane dla \"Pana Tadeusza\" i \"Robinsona Crusoe\") sugerują, że dla pewnych danych wyniki funkcji mogą być niewiarygodne.",
   "id": "6f9abd86f7dec29f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Znaczenie tekstu w analizie**: Na przykładzie dopasowania artykułu z Bulbapedii o Bulbasaurze oraz \"Robinsonie Crusoe\" z językiem angielskim można zauważyć, że choć obydwa teksty były teoretycznie napisane w tym samym języku to dopasowanie dla \"Robinsona Crusoe\" jest znacznie wyższe (dla k=1000 jest to około 0.8, a dla artykułu z wiki mniej niż 0.5). Wynika to z tego, że w artykule na wiki występuje wiele nazw własnych które nie występują w języku angielskim i ich duża ilość zmniejsza stosunek słów rzeczywiście występujących w języku angielskim do wszystkich słów występujących w tekście. Świadczy to o dużym znaczeniu doboru tekstu dla precyzji analizy z użyciem badanej funkcji.",
   "id": "563b44a83d3af749"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Znaczenie doboru języków**: Dobór języków ma duże znaczenie dla analizy języka tekstu. Na podstawie wszystkich wykresów możemy zauważyć, że teksty angielskie mają względnie wysokie dopasowanie z językiem polskim oraz teksty polskie z językiem angielskim. Dzieje się tak ponieważ w obydwu tych językach popularne są słowa pisane tak samo np. \"i\" oraz \"a\". Dla kontrastu tekst dla k równych 3,10 lub 100. Miał dopasowania bliskie zeru z językiem angielskim oraz polskim, a teksty w językach angielskim i polskim miały praktycznie zerowe dopasowania z językiem francuskim.",
   "id": "c7fb17ecfc7af74c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Wnoski na temat częstości odmieniania słów**: Zauważmy, że mimo że \"Pan Tadeusz\" jest napisany w języku polskim to jego dopasowanie (dla k=1000) z natywnym językiem równe około 0.4 jest zauważalnie mniejsze niż dopasowanie \"Robinsona Crusoe\" (ok. 0.8) napisanego w języku angielskim z jego natywnym językiem. Jest to wynik tego, że słowa w języku polskim porpzez bogatą odmianę mają równiej rozłożone częstotliwości występowania (odniesienie do tego samego stanu w języku polskim jest realizowane za pomocą wielu słów różniących się jedynie odmianą). Dlatego słowo odnoszące się do tego samego w języku polskim może mieć nawet kilkukrotnie mniejszą częstotliwość niż agnielski odpowiednik. Sugeruje to, że języki dla których teksty w nich napsiane mają niższe wartości dopasowania mają bogatszą odmianę słów.",
   "id": "5cbc5c807bfdda5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
